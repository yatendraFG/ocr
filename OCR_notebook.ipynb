{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMXhgD4wZFf58+bGgyGMAv5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priyankaverma2024/Project-10-OCR-System-with-YOLOv3-for-Text-Detection3/blob/main/OCR_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Setup (Google Colab)"
      ],
      "metadata": {
        "id": "fOXOlF4UtYmT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpqNqBmpqfHm",
        "outputId": "f3f4ebf0-10b0-42ce-f13c-693038cec4a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Tesseract OCR engine and the Python wrapper (pytesseract)\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!pip install opencv-python-headless # For OpenCV"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hr__JXwsa0H",
        "outputId": "ee4c44b1-3ed3-4ea9-da80-606238db2655"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,930 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,245 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,721 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,212 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,901 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,546 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [38.4 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [113 kB]\n",
            "Fetched 21.1 MB in 2s (8,969 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.2.1)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.warnings =\"ignore\""
      ],
      "metadata": {
        "id": "NmlC9I2GCY-D"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation: Accessing Your Images"
      ],
      "metadata": {
        "id": "n_FRCGDStsTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the path to your images folder on Google Drive\n",
        "image_folder_path = '/content/drive/MyDrive/OCR_Project_dataset/' # Make sure this path is correct\n",
        "\n",
        "# List all files in the image folder\n",
        "try:\n",
        "    image_files = [f for f in os.listdir(image_folder_path) if os.path.isfile(os.path.join(image_folder_path, f))]\n",
        "    print(f\"Found {len(image_files)} images in {image_folder_path}\")\n",
        "    # print(\"First few image files:\", image_files[:5]) # Optional: print a few names to check\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The folder {image_folder_path} was not found. Please check the path.\")\n",
        "    image_files = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prlCzXo6tzwm",
        "outputId": "521362ec-3a37-4e3d-9175-e658dcc9efdf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 103 images in /content/drive/MyDrive/OCR_Project_dataset/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Core OCR Workflow: Image Preprocessing and Text Extraction"
      ],
      "metadata": {
        "id": "f_b28TUVvUYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "import numpy as np\n",
        "from PIL import Image # Pytesseract works well with PIL Images\n",
        "\n",
        "def preprocess_image_for_ocr(image_path):\n",
        "    \"\"\"\n",
        "    Loads an image, preprocesses it for OCR, and returns the preprocessed image.\n",
        "    Preprocessing steps include:\n",
        "    1. Read image\n",
        "    2. Resize (optional, here commented out but shown as per document [cite: 10])\n",
        "    3. Convert to grayscale [cite: 11]\n",
        "    4. Apply Gaussian blur [cite: 11]\n",
        "    5. Apply thresholding (Otsu's method) [cite: 12]\n",
        "    6. Invert colors (black text on white background) [cite: 14]\n",
        "    \"\"\"\n",
        "    try:\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            print(f\"Warning: Could not read image {image_path}. Skipping.\")\n",
        "            return None\n",
        "\n",
        "        # 2. Resize (Optional - your document mentions blowing up small images 3x)\n",
        "        # If your images are very small, resizing can help.\n",
        "        # Example: img = cv2.resize(img, None, fx=3, fy=3, interpolation=cv2.INTER_CUBIC) [cite: 10]\n",
        "        # For now, let's assume original size is okay or this needs tuning per image.\n",
        "\n",
        "        # 3. Convert to grayscale\n",
        "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # 4. Apply Gaussian blur to smooth the image\n",
        "        # The kernel size (e.g., (5,5)) can be tuned. (1,1) or (3,3) for less blur if text is sharp.\n",
        "        # Your document mentions a \"small Gaussian blur\".\n",
        "        blurred_img = cv2.GaussianBlur(gray_img, (1, 1), 0) # Using a very small kernel [cite: 11]\n",
        "\n",
        "        # 5. Apply thresholding\n",
        "        # Otsu's method automatically determines the optimal threshold value. [cite: 12]\n",
        "        # This creates a binary image (black and white).\n",
        "        # The document mentions getting white text on a black background first.\n",
        "        _, thresholded_img_white_text = cv2.threshold(blurred_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "        # 6. Invert colors: Tesseract often performs better with black text on a white background. [cite: 14]\n",
        "        preprocessed_img = cv2.bitwise_not(thresholded_img_white_text)\n",
        "\n",
        "        return preprocessed_img\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during preprocessing image {image_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_text_from_image(preprocessed_img):\n",
        "    \"\"\"\n",
        "    Extracts text from a preprocessed image using Pytesseract.\n",
        "    \"\"\"\n",
        "    if preprocessed_img is None:\n",
        "        return \"Error: Preprocessed image is None.\"\n",
        "    try:\n",
        "        # Convert OpenCV image (NumPy array) to PIL Image\n",
        "        pil_img = Image.fromarray(preprocessed_img)\n",
        "        custom_config = r'--oem 3 --psm 6' # Example Pytesseract configuration\n",
        "        text = pytesseract.image_to_string(pil_img, config=custom_config)\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error during text extraction: {e}\")\n",
        "        return f\"Error extracting text: {e}\"\n",
        "\n",
        "# Example of processing one image:\n",
        "if image_files:\n",
        "    sample_image_path = os.path.join(image_folder_path, image_files[0])\n",
        "    print(f\"\\nProcessing sample image: {sample_image_path}\")\n",
        "\n",
        "    preprocessed_image = preprocess_image_for_ocr(sample_image_path)\n",
        "\n",
        "    if preprocessed_image is not None:\n",
        "        # To display the image in Colab (optional)\n",
        "        # from google.colab.patches import cv2_imshow\n",
        "        # print(\"Preprocessed Image (for OCR):\")\n",
        "        # cv2_imshow(preprocessed_image)\n",
        "\n",
        "        extracted_text = extract_text_from_image(preprocessed_image)\n",
        "        print(\"\\n--- Extracted Text (from sample image) ---\")\n",
        "        print(extracted_text)\n",
        "        print(\"--- End of Extracted Text ---\")\n",
        "    else:\n",
        "        print(f\"Could not preprocess {sample_image_path}\")\n",
        "\n",
        "else:\n",
        "    print(\"No image files found to process as a sample.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gjtG5YmvUvs",
        "outputId": "72d2ae37-ceba-40d2-bcf1-84e6efb46e3d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing sample image: /content/drive/MyDrive/OCR_Project_dataset/thyrocare_0_122.jpg\n",
            "\n",
            "--- Extracted Text (from sample image) ---\n",
            "a i\n",
            "hyrovere ; Ler = | st\n",
            "-37/1,7TC MIDC,Turbhe, bs tetas tdi dl yrQ car e\n",
            "eet ioe ne omen Think Thyroid. Think Thyrecare.\n",
            "lo ER ee BS eee mae a Se rd\n",
            "etree TP eee roam est ea dee Ls aarareali eae aneehcada\n",
            "rend Pee Sent Stroy Pret ee\n",
            "er. BY aes (7874357519), KALPANA MEDICOS AND CITY\n",
            "Wepre rer me Smee Cr a\n",
            "\n",
            "ey fre cry\n",
            "TEST NAME TECHNOLOGY VALUE UNITS REFERENCE RANGE\n",
            "\n",
            "See Met OL a fone a 7 veo too tel)\n",
            "\n",
            "Drees en] row 5 eed\n",
            "\n",
            "Der ess Ra ee fot) CLLA 2.14 Prt da  Ee\n",
            "\n",
            "‘ A\n",
            "\n",
            "Comments: SUGGESTING Bri tL ee\n",
            "\n",
            "Rail fe\n",
            "\n",
            "er\n",
            "\n",
            "Beer aru en alt Pfeil aml ae\n",
            "\n",
            "ee art ee oy LUMINESCENT IMMUNO ASSAY\n",
            "\n",
            "se eB a LUMINESCENT IMMUNO ASSAY\n",
            "\f\n",
            "--- End of Extracted Text ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processing All Images and Saving Results"
      ],
      "metadata": {
        "id": "3SAGs4nbwGOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "results_list = []\n",
        "output_csv_path = '/content/drive/MyDrive/ocr_project_results/extracted_thyrocare_data.csv' # Choose your output path\n",
        "os.makedirs(os.path.dirname(output_csv_path), exist_ok=True) # Create folder if it doesn't exist\n",
        "\n",
        "if image_files:\n",
        "    print(f\"\\nStarting batch processing of {len(image_files)} images...\")\n",
        "    for i, image_file_name in enumerate(image_files):\n",
        "        start_time = time.time()\n",
        "        print(f\"Processing image {i+1}/{len(image_files)}: {image_file_name}...\")\n",
        "        current_image_path = os.path.join(image_folder_path, image_file_name)\n",
        "\n",
        "        preprocessed_img = preprocess_image_for_ocr(current_image_path)\n",
        "\n",
        "        if preprocessed_img is not None:\n",
        "            text = extract_text_from_image(preprocessed_img)\n",
        "            results_list.append({'image_filename': image_file_name, 'extracted_text': text})\n",
        "            print(f\"  Extracted text (first 100 chars): {text[:100].replace(chr(10), ' ')}...\") # Show a snippet\n",
        "        else:\n",
        "            results_list.append({'image_filename': image_file_name, 'extracted_text': 'Error in preprocessing'})\n",
        "            print(f\"  Skipped due to preprocessing error.\")\n",
        "\n",
        "        end_time = time.time()\n",
        "        print(f\"  Time taken: {end_time - start_time:.2f} seconds.\")\n",
        "\n",
        "\n",
        "    # Create a Pandas DataFrame and save to CSV\n",
        "    df_results = pd.DataFrame(results_list)\n",
        "    try:\n",
        "        df_results.to_csv(output_csv_path, index=False, encoding='utf-8')\n",
        "        print(f\"\\nSuccessfully saved extracted data to: {output_csv_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError saving CSV file: {e}\")\n",
        "        # Fallback: print to console if saving fails\n",
        "        # print(\"\\n--- All Extracted Data ---\")\n",
        "        # for item in results_list:\n",
        "        #     print(f\"Image: {item['image_filename']}\\nText: {item['extracted_text']}\\n---\")\n",
        "\n",
        "else:\n",
        "    print(\"No image files found to process for batch operation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1yz0s3UwTvX",
        "outputId": "adcaf379-d80d-4708-912f-945eeafa79ab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting batch processing of 103 images...\n",
            "Processing image 1/103: thyrocare_0_122.jpg...\n",
            "  Extracted text (first 100 chars): a i hyrovere ; Ler = | st -37/1,7TC MIDC,Turbhe, bs tetas tdi dl yrQ car e eet ioe ne omen Think Thy...\n",
            "  Time taken: 4.89 seconds.\n",
            "Processing image 2/103: thyrocare_0_511.jpg...\n",
            "  Extracted text (first 100 chars): \"ff CT Ue . By ak #3 CAP mui Ct ome ; aS A Note lei he Ces a SR ee ede nk Rem OR ee Lr ee eM al kl ....\n",
            "  Time taken: 3.69 seconds.\n",
            "Processing image 3/103: thyrocare_0_421.jpg...\n",
            "  Extracted text (first 100 chars): } , a | i’ sw a, eT aE OO ae a ete * en me nr MY Corporate Office : Teyrocare Technologies Limited @...\n",
            "  Time taken: 5.25 seconds.\n",
            "Processing image 4/103: thyrocare_0_532.jpg...\n",
            "  Extracted text (first 100 chars): ye eee agama Boe iebiccee th ic 5, Hokisinla Lasidinbl EMC, Torte aioe nee a REPORT = ¥ bea eda) Se ...\n",
            "  Time taken: 3.49 seconds.\n",
            "Processing image 5/103: thyrocare_0_36.jpg...\n",
            "  Extracted text (first 100 chars): ik, Moat 700 O59 The Tyron, Ter 0 Ee ae yy ianndagaea ea Se a stencil eR aes Elle ee lenient shen Md...\n",
            "  Time taken: 4.14 seconds.\n",
            "Processing image 6/103: thyrocare_0_123.jpg...\n",
            "  Extracted text (first 100 chars): on a = - ena rene Caer Neg sui See is ee 7c Pete ce) aa ~ee— De hs eT eR ee tare ee eR Me Re , CORP ...\n",
            "  Time taken: 3.97 seconds.\n",
            "Processing image 7/103: thyrocare_0_517.jpg...\n",
            "  Extracted text (first 100 chars): / at: ¥ ‘Thyrocere : Ss CAP en er Sear ote ‘ J Ricerca ae yTQ care’ Cet e) rae hain re Think Thyroid...\n",
            "  Time taken: 3.04 seconds.\n",
            "Processing image 8/103: thyrocare_0_447.jpg...\n",
            "  Extracted text (first 100 chars): am ld ; ete Sk Or Nad ows nd ed in tne teri al LyTQ care” eer oe 2a a Oe sd Ce ae ee ee ei PO eee ha...\n",
            "  Time taken: 2.75 seconds.\n",
            "Processing image 9/103: thyrocare_0_640.jpg...\n",
            "  Extracted text (first 100 chars): a a -_ _ oan + OTN sui) Pare en bes J Pca ladle yrocare fiphbnibire abe ee Hepat Meare eee Corporate...\n",
            "  Time taken: 2.78 seconds.\n",
            "Processing image 10/103: thyrocare_0_657.jpg...\n",
            "  Extracted text (first 100 chars): _f ea aa BUN ice, — csniaahdaaaiel diag KML <a Roem) et Ss dabiehicieiehider Dodie Lok VELMA a ee eT...\n",
            "  Time taken: 4.39 seconds.\n",
            "Processing image 11/103: thyrocare_0_1861.jpg...\n",
            "  Extracted text (first 100 chars): se rad 9 : Thyra er | aiid aie katie OLA . enn) Daeg Sc eehiheR ee  e SL Rae ee Rs Leelee C ee eee S...\n",
            "  Time taken: 5.89 seconds.\n",
            "Processing image 12/103: thyrocare_0_1248.jpg...\n",
            "  Extracted text (first 100 chars): 7 as \" a ECO PR oem te eS ACCREDITED yrocare’ Tee) 5 OR RC cd Corporate Office : Thyrocare Technolog...\n",
            "  Time taken: 2.11 seconds.\n",
            "Processing image 13/103: thyrocare_0_1174.jpg...\n",
            "  Extracted text (first 100 chars): aT: a TPR ren Te es ) Roan al yro care’ LED ae — SL ala eT eR rr eee dC EERE Lee P Re air te te ir a...\n",
            "  Time taken: 2.49 seconds.\n",
            "Processing image 14/103: thyrocare_0_757.jpg...\n",
            "  Extracted text (first 100 chars): Pea ony oS oer yro care? era ic A a ai Fee OTR ee cen eR De Re a LL) -_ Cc ee creel eeaia REPORT a P...\n",
            "  Time taken: 4.11 seconds.\n",
            "Processing image 15/103: thyrocare_0_912.jpg...\n",
            "  Extracted text (first 100 chars): PROCESSED AT: Li aietaaahed EN eter N=) a te MaDc,turoe, Ss Ae me Wi excOler: kaw Se eer! nee es ae ...\n",
            "  Time taken: 3.20 seconds.\n",
            "Processing image 16/103: thyrocare_0_838.jpg...\n",
            "  Extracted text (first 100 chars): oa Ecce path 7108 e a Ao Riese len emnatlahall rN creme ad Ge Nod Ee vnront uatbmteaicien Be ge ce e...\n",
            "  Time taken: 3.86 seconds.\n",
            "Processing image 17/103: thyrocare_0_1001.jpg...\n",
            "  Extracted text (first 100 chars): oe I r ~ a [ lala ‘iat TO at wots “nian pape are ae Alea apathetic +3 cathe sins “ acral wale eb se ...\n",
            "  Time taken: 5.65 seconds.\n",
            "Processing image 18/103: thyrocare_0_1374.jpg...\n",
            "  Extracted text (first 100 chars): cs antaccecg te Li a BR en eM Cee eT art ae rocar er aE tre coer mere Rt) Ce MR a » ‘ Corporate Offi...\n",
            "  Time taken: 3.24 seconds.\n",
            "Processing image 19/103: thyrocare_0_1433.jpg...\n",
            "  Extracted text (first 100 chars): ~ aa 7 x cd e@r-\\] aun eee a i Freese Mineo er: keg LU Ry ean a Ce OU aed le eter et ee Deu a aL ae ...\n",
            "  Time taken: 2.65 seconds.\n",
            "Processing image 20/103: thyrocare_0_1711.jpg...\n",
            "  Extracted text (first 100 chars): ea -  rocare fy =caP, Th  UE eae ross) oat a) 00) care’  Mate Nees) hao — Think Thyroid. Think Thyro...\n",
            "  Time taken: 2.75 seconds.\n",
            "Processing image 21/103: thyrocare_0_2838.jpg...\n",
            "  Extracted text (first 100 chars): iG a ; agree kl got all Aide Phagronh: The. Tinea Y : he ee eae a Lntdyh ig ep ceteaten i nia aA ama...\n",
            "  Time taken: 5.24 seconds.\n",
            "Processing image 22/103: thyrocare_0_2177.jpg...\n",
            "  Extracted text (first 100 chars): been eT - 7 aed “CAP sua Tan Te * ae i Lesa W168) ro Ries ena a Se RR ans Corporate Office : Thyroca...\n",
            "  Time taken: 3.20 seconds.\n",
            "Processing image 23/103: thyrocare_0_1915.jpg...\n",
            "  Extracted text (first 100 chars): — oun =a yrocar See eclaeeae taiedaal hae  Neale lal sia i scqeebio dooce cng ap ceva Aagdideaab inh...\n",
            "  Time taken: 4.09 seconds.\n",
            "Processing image 24/103: thyrocare_0_2649.jpg...\n",
            "  Extracted text (first 100 chars): : ail sy a. = Se AE ee tee te oe a MP Red, Kolkata-700 059 Re Pye ban habla eal Re lat ee, ~ cake be...\n",
            "  Time taken: 5.07 seconds.\n",
            "Processing image 25/103: thyrocare_0_2300.jpg...\n",
            "  Extracted text (first 100 chars): u / = BU aces ? Tyee De we una o bol eae Mehr) BR Sra eahtide dete beetle otk SURO a ne fs See Uc na...\n",
            "  Time taken: 3.14 seconds.\n",
            "Processing image 26/103: thyrocare_0_2737.jpg...\n",
            "  Extracted text (first 100 chars): af wok se eee LOR rn m a mode) Baa debe RPE m eee ee Ty CD TLE EU ce te et cee eee . ed PCs ela ei) ...\n",
            "  Time taken: 2.86 seconds.\n",
            "Processing image 27/103: thyrocare_0_2866.jpg...\n",
            "  Extracted text (first 100 chars): | ; LL 7 L PROCESSED AT : _ Boy ce ON aa) PT mae eae ‘ ae ) Pica Tide all yrocare’ eettred sr 2 eS F...\n",
            "  Time taken: 3.61 seconds.\n",
            "Processing image 28/103: thyrocare_0_2505.jpg...\n",
            "  Extracted text (first 100 chars): een ad pon ; Det ek ee oS Feat a yrocare’ Cdr) a rn Think Thyroid, Think Thyrocare. Corporate Office...\n",
            "  Time taken: 4.53 seconds.\n",
            "Processing image 29/103: thyrocare_0_2691.jpg...\n",
            "  Extracted text (first 100 chars): ee _ _— 3 CAP swt re peg Re Nae yrocare rec! ae Aaa a Sr ae Rea De Beer sc Mpa. ects Ne erry 4 @© 02...\n",
            "  Time taken: 3.13 seconds.\n",
            "Processing image 30/103: thyrocare_0_2841.jpg...\n",
            "  Extracted text (first 100 chars): | ae Th satan Poot ; we Towors 1, RAA/36, Raghunathpur, we Pe ee med mes Dk planiindicgubhi mie eRe ...\n",
            "  Time taken: 3.40 seconds.\n",
            "Processing image 31/103: thyrocare_0_3804.jpg...\n",
            "  Extracted text (first 100 chars): 4 | De rae ces a chacatdel Fea 2 CAP Th Pen tore i bes iW ACCREDITED” yO or hao ee eee ender Farah =...\n",
            "  Time taken: 4.50 seconds.\n",
            "Processing image 32/103: thyrocare_0_3439.jpg...\n",
            "  Extracted text (first 100 chars): / \" : biracial “a = CAP Th De Ree x5 2 Frere Ta aed yrocare _ ae avomaineere ey Sis Leed Poe Think T...\n",
            "  Time taken: 3.05 seconds.\n",
            "Processing image 33/103: thyrocare_0_3333.jpg...\n",
            "  Extracted text (first 100 chars): a _ »  gCAP Th Se eas te rain eee yro car Peer eae! ec Pe reece Dr a RL a Corporate Office : Thyroca...\n",
            "  Time taken: 3.22 seconds.\n",
            "Processing image 34/103: thyrocare_0_3813.jpg...\n",
            "  Extracted text (first 100 chars): Feta Pa Be Ca Ceti ota jceere ~ VIP Road, Kolkata-700 059 GRU Ma ae Corporate Office : Teyrocare Tec...\n",
            "  Time taken: 3.18 seconds.\n",
            "Processing image 35/103: thyrocare_0_3558.jpg...\n",
            "  Extracted text (first 100 chars): y p a AWN ace. i ne ree -snedlatanaaeeicta ae totic uae ae pik fd LT eden Bi is (-  eeeiedcenbiserdt...\n",
            "  Time taken: 4.94 seconds.\n",
            "Processing image 36/103: thyrocare_0_4046.jpg...\n",
            "  Extracted text (first 100 chars): ‘ ea eR Dr buallacag-. wt “oo BE eek gpa crassa phat, 2 : — EPOKT ——  a eal Deeded ee eee nr renal p...\n",
            "  Time taken: 3.01 seconds.\n",
            "Processing image 37/103: thyrocare_0_3753.jpg...\n",
            "  Extracted text (first 100 chars): . , an fo ea a = eae reer irene fa Ree TE pen 8 HES Sept ete este me wali eres = REPROD eae ee ccemu...\n",
            "  Time taken: 3.82 seconds.\n",
            "Processing image 38/103: thyrocare_0_2885.jpg...\n",
            "  Extracted text (first 100 chars): é Dn aS ; ore Sane Pree ae ‘ oS a ACCREDITED yrocare’ Navi Mumbal-400 703, ona meee SR head Cr eR en...\n",
            "  Time taken: 4.36 seconds.\n",
            "Processing image 39/103: thyrocare_0_2987.jpg...\n",
            "  Extracted text (first 100 chars): eet “ Pen! poet = ama Se me et ee 3. oe ia a anette beRepe agtoeby, iemeeblie cE 3 ‘ Oe pa i — REPOR...\n",
            "  Time taken: 4.16 seconds.\n",
            "Processing image 40/103: thyrocare_0_3414.jpg...\n",
            "  Extracted text (first 100 chars): Ly nl “s a. : ae Hinigesl Gita “pa eal panes. eee ny Spr reseiiafeastin sn, $ Jie ine eg hes BSG VRR...\n",
            "  Time taken: 3.19 seconds.\n",
            "Processing image 41/103: thyrocare_0_4790.jpg...\n",
            "  Extracted text (first 100 chars): a ld Se cen EOF N 2 ‘ DET oy earn Thyra [or hase ee eat fen 2a ER i Ce ae en Te a eet eee ieee Rente...\n",
            "  Time taken: 2.69 seconds.\n",
            "Processing image 42/103: thyrocare_0_4523.jpg...\n",
            "  Extracted text (first 100 chars): site Samer” seetimedie (hy Racial eae i J Rd - en en a ee fhe ly EA ee gee chp ewes apalnbe\\baiapeE ...\n",
            "  Time taken: 5.78 seconds.\n",
            "Processing image 43/103: thyrocare_0_4385.jpg...\n",
            "  Extracted text (first 100 chars): SESSED AT: _ _ Wer \\ 2) Th PP) em cS) ACCREDITED” yrocare enfant Ca fae ain — SE Corporote Office - ...\n",
            "  Time taken: 3.06 seconds.\n",
            "Processing image 44/103: thyrocare_0_4670.jpg...\n",
            "  Extracted text (first 100 chars): Denn ea , PPR E ne i A 4 cardi al yrQ ro) ow See cde oe RL ki eke eR ere ec ree REM aL ae OR aa Seer...\n",
            "  Time taken: 3.19 seconds.\n",
            "Processing image 45/103: thyrocare_0_4557.jpg...\n",
            "  Extracted text (first 100 chars): _ athe \" = Siple seen ee 7 hoes eoaeetaal Sora Ayashi alicia od : eee ee pelea 4 b ily neo pagina ne...\n",
            "  Time taken: 5.20 seconds.\n",
            "Processing image 46/103: thyrocare_0_4468.jpg...\n",
            "  Extracted text (first 100 chars): _f Lae oes a Le! roe ern au 7 Dass Tee b i eS Kee  See ae ean SR Roa) ee RD EUR A Lk GRC RePEc one a...\n",
            "  Time taken: 2.43 seconds.\n",
            "Processing image 47/103: thyrocare_0_4748.jpg...\n",
            "  Extracted text (first 100 chars): oom Pe mae TV TE Care SS “Tecra Tega iS lger eT semaine staat ce Sea) Pe ataae aol eS od Pee era Bea...\n",
            "  Time taken: 3.72 seconds.\n",
            "Processing image 48/103: thyrocare_0_4618.jpg...\n",
            "  Extracted text (first 100 chars): ~/ P  bapa Fos 5 CAI Th  Lac ae es, a Fae ney yroO care’ eRe! ronan a De  ne eee eee Sere ed eR EUR ...\n",
            "  Time taken: 4.07 seconds.\n",
            "Processing image 49/103: thyrocare_0_4683.jpg...\n",
            "  Extracted text (first 100 chars): \\ ee ‘Thyrocere 5 Ler Ned ‘h es ey ecap,. Thyrocare Navi Mumbal-400 703 cain re as DL Re Corporcte O...\n",
            "  Time taken: 3.10 seconds.\n",
            "Processing image 50/103: thyrocare_0_4498.jpg...\n",
            "  Extracted text (first 100 chars): ra rocare W107\") aun TES ne eS) catia yrocare ee mix) rane a Fe a RU RL nT eB ere De ot PEER OM Mi S...\n",
            "  Time taken: 2.72 seconds.\n",
            "Processing image 51/103: thyrocare_0_5640.jpg...\n",
            "  Extracted text (first 100 chars): y . rs mat ‘ BW Ngee citable aaa hac Urea aa Deemed Be Rs celeebahi iil betes Luk DEUeee a een teas....\n",
            "  Time taken: 3.27 seconds.\n",
            "Processing image 52/103: thyrocare_0_5338.jpg...\n",
            "  Extracted text (first 100 chars): ~ rn , Sela bpok Ester \\) aus Pes ne od Resa NA xee ler: ee eer) oak SR lee eee eee eR REL RR a hak ...\n",
            "  Time taken: 3.61 seconds.\n",
            "Processing image 53/103: thyrocare_0_5074.jpg...\n",
            "  Extracted text (first 100 chars): yy aT: bah del q Elen N22 Uc) Pee eae eet ae Road eae yro care’ eee! Baran mae DR Re 7 ee ee ee de B...\n",
            "  Time taken: 3.26 seconds.\n",
            "Processing image 54/103: thyrocare_0_5357.jpg...\n",
            "  Extracted text (first 100 chars): Ls 2 - an an Ff & 4 2 r - / IRR ee Baia hes rhage _L oa trgu sou cdabaag Enh <n REPORT —— = TP cea a...\n",
            "  Time taken: 4.13 seconds.\n",
            "Processing image 55/103: thyrocare_0_4979.jpg...\n",
            "  Extracted text (first 100 chars): x rem a RUE Arti ae Le) Thnk Ti 4 deed Re Raa eae Te See DUO Tata Tet cee escaca nd PECs. are Petia ...\n",
            "  Time taken: 2.57 seconds.\n",
            "Processing image 56/103: thyrocare_0_5608.jpg...\n",
            "  Extracted text (first 100 chars): — Po rin - ; Uhhh cot gi eri oe Cisse a aimompeleagr ec cis 2 CEE A canoe lees aa sa ruint a ee) er ...\n",
            "  Time taken: 5.39 seconds.\n",
            "Processing image 57/103: thyrocare_0_5816.jpg...\n",
            "  Extracted text (first 100 chars): g ball atperinadeeetententeathdal i =  Pr MCh em eC Se PT m feelers ¢ De ole n) SL a  Mee Wei Techno...\n",
            "  Time taken: 3.21 seconds.\n",
            "Processing image 58/103: thyrocare_0_5879.jpg...\n",
            "  Extracted text (first 100 chars): PROCESSED AT: Thyrocere neo 4 CAP en Hidden iS Ce canal yrocare pee seeniiandle ene eke! nn Dn es Ri...\n",
            "  Time taken: 3.03 seconds.\n",
            "Processing image 59/103: thyrocare_0_5858.jpg...\n",
            "  Extracted text (first 100 chars): US a OWivsiee bea ib Dade aaa CUTE ard aii  De ener Ma LeleahieetR ieee ee LR DURA ae ey tee NEE EC ...\n",
            "  Time taken: 4.42 seconds.\n",
            "Processing image 60/103: thyrocare_0_5503.jpg...\n",
            "  Extracted text (first 100 chars): — ee Sass yy BB insect). ae i gargs tcl esa srechicdhcaleS: ahs . — . AEFOR) gr ane cael ey Pee ue) ...\n",
            "  Time taken: 4.07 seconds.\n",
            "Processing image 61/103: thyrocare_0_6698.jpg...\n",
            "  Extracted text (first 100 chars): as r | i poses isla ane pepe : : Finest pale iain gti aia head soi leis gblangy itis , a corona elas...\n",
            "  Time taken: 3.85 seconds.\n",
            "Processing image 62/103: thyrocare_0_5928.jpg...\n",
            "  Extracted text (first 100 chars): ; Se ee EET ee ho Be egy ice aaligamge a ee 0! . 7 i ata) Per a So ca ice reer gs eal Pera pnp) ped ...\n",
            "  Time taken: 3.95 seconds.\n",
            "Processing image 63/103: thyrocare_0_6716.jpg...\n",
            "  Extracted text (first 100 chars): / rs ¥ cael SAS Ba FN) Th Pe een ee eS Js og yrocare’ jl Deen) ano meee RR atl Oe eR ere Re NR UMAR ...\n",
            "  Time taken: 3.61 seconds.\n",
            "Processing image 64/103: thyrocare_0_6884.jpg...\n",
            "  Extracted text (first 100 chars): PROCESSED AT: ee ye oven tee ‘ bx A) ACCREDITED yrocare De cr) Perak oom SM RS ee eee te Rea ee Le r...\n",
            "  Time taken: 2.67 seconds.\n",
            "Processing image 65/103: thyrocare_0_5896.jpg...\n",
            "  Extracted text (first 100 chars): ‘ 1 ii ei get atacand aENRNy a REMORT . a  = toa) Deeaetant cna ee sme Fee aera NE el pasta aneas OS...\n",
            "  Time taken: 3.32 seconds.\n",
            "Processing image 66/103: thyrocare_0_6185.jpg...\n",
            "  Extracted text (first 100 chars): a ~ so ae. ook Dn oa a SO li as gearing eB SE ge gp rn pee naam sia a REPOR? Sd Pao preter aes ior t...\n",
            "  Time taken: 5.10 seconds.\n",
            "Processing image 67/103: thyrocare_0_6214.jpg...\n",
            "  Extracted text (first 100 chars): cae eal Bhs) y s Ss Na 108:  apnieetnach hii aeataliont 1 la Liege hess onset GRA ndadstlagend-ekanw...\n",
            "  Time taken: 3.73 seconds.\n",
            "Processing image 68/103: thyrocare_0_6743.jpg...\n",
            "  Extracted text (first 100 chars): p af ra - _ b By Reon Ea oye) Na) i— PRE em te mow Retinal yrocare’ Cee iy een a Rk Pe ee te eR Lo R...\n",
            "  Time taken: 2.67 seconds.\n",
            "Processing image 69/103: thyrocare_0_6222.jpg...\n",
            "  Extracted text (first 100 chars): ‘ae oO 7 OCG San aaa “ovo Tana CERO eee Pehenetind, 7 +B Slo Esher pea gegen sia Lines praises R e :...\n",
            "  Time taken: 4.30 seconds.\n",
            "Processing image 70/103: thyrocare_0_6723.jpg...\n",
            "  Extracted text (first 100 chars): 4 Da - RT rN “CAP aa ae PPR re vs i] ACCREDTEDW yrocare’ eat Eeosietennnns DR a UmLiKy oon ee BURL R...\n",
            "  Time taken: 3.82 seconds.\n",
            "Processing image 71/103: thyrocare_0_7082.jpg...\n",
            "  Extracted text (first 100 chars): wi rr _ ) Thyrocera in er \\) Th Pee Rae tise ee Peet Nicole eg Cee Annee a Re Ci ee eae Tee RMU EMU ...\n",
            "  Time taken: 2.49 seconds.\n",
            "Processing image 72/103: thyrocare_0_7109.jpg...\n",
            "  Extracted text (first 100 chars): Fes cuncinal ead ace s801 RS eM Celtta yroc ci VIP Road, Kolkata-700 059 a TE, , a abet RU Le SSE a ...\n",
            "  Time taken: 3.56 seconds.\n",
            "Processing image 73/103: thyrocare_0_7083.jpg...\n",
            "  Extracted text (first 100 chars): Pa i a oa i er ee. te HY ICCalse eal ky a wok snes prpushinta inal nsebiangprelausaci ii tie — 170\")...\n",
            "  Time taken: 5.09 seconds.\n",
            "Processing image 74/103: thyrocare_0_7601.jpg...\n",
            "  Extracted text (first 100 chars): ras _ meme Cs ESO NT ae Ce ers a yrocare® Reenter ry an aa as Se eae OT eR eee Bere eT Re oe Os eee ...\n",
            "  Time taken: 2.91 seconds.\n",
            "Processing image 75/103: thyrocare_0_7219.jpg...\n",
            "  Extracted text (first 100 chars): fi Li ES , 7 Des7P ata onion Pas yi ACCREDTEDW” yrocare Se ELEY Pareto oun RR ai ical Corporate Offi...\n",
            "  Time taken: 3.31 seconds.\n",
            "Processing image 76/103: thyrocare_0_7571.jpg...\n",
            "  Extracted text (first 100 chars): aii ne = i Perea uate eo] cca yo he Pee i LL oi ent eer ei eek DEV RG aL oe Ue LES reM Ess eM Tet ao...\n",
            "  Time taken: 2.75 seconds.\n",
            "Processing image 77/103: thyrocare_0_7075.jpg...\n",
            "  Extracted text (first 100 chars): — fn a Lees ecap, Th e ate paced Mi ceele: Le, ere nee, MA Thi Tyo, Tin Thyrocare: ew Rte ere et ar ...\n",
            "  Time taken: 3.98 seconds.\n",
            "Processing image 78/103: thyrocare_0_7791.jpg...\n",
            "  Extracted text (first 100 chars): a sentences ie Th uddapcoahe YIOca lowers U1, RAA/36, Raghunathpur,  at Co ee eee osots) Be Maa:  Co...\n",
            "  Time taken: 3.67 seconds.\n",
            "Processing image 79/103: thyrocare_0_7635.jpg...\n",
            "  Extracted text (first 100 chars): a / amas tal ae. sa | I lVICee Sake Maa aus ei Leakey MR sal culeih dil ele eR SER eee eT eee ie hee...\n",
            "  Time taken: 3.29 seconds.\n",
            "Processing image 80/103: thyrocare_0_7758.jpg...\n",
            "  Extracted text (first 100 chars): J ) Len ay P : ‘Thyrocere Wer V2 Th DEPOT a Poets vl y rocare’ ea anniek Aan es  lee re eee ek De aa...\n",
            "  Time taken: 3.52 seconds.\n",
            "Processing image 81/103: thyrocare_0_7805.jpg...\n",
            "  Extracted text (first 100 chars): —v in on : i Si die See Wi Pe Re se 1) oie W/O ler: ek) ia, EL en ea eee ee a ae ad 7 COE rai laa RE...\n",
            "  Time taken: 3.44 seconds.\n",
            "Processing image 82/103: thyrocare_0_8302.jpg...\n",
            "  Extracted text (first 100 chars): 4 SED AT: a. SUN iio Se aed ge ECan at sh pe MeL ei] Slate Be ahi beh ee cE LEU ERL a ee ee EL EE os...\n",
            "  Time taken: 2.89 seconds.\n",
            "Processing image 83/103: thyrocare_0_8214.jpg...\n",
            "  Extracted text (first 100 chars): \" ‘ Ler 7 Laat een 4= CAP Th D-37/1,1TC MIDC,Turbhe, 5 A ACCREDITED ryro care’ Nev! Mumbel-4o0 703 e...\n",
            "  Time taken: 4.52 seconds.\n",
            "Processing image 84/103: thyrocare_0_8491.jpg...\n",
            "  Extracted text (first 100 chars): : a * _ 7 r Vy poise WUshnewie: cu. fn, ENS oe ian te. 2 shag lat ig gts ie RR SIE eae MUA = ‘ A Rad...\n",
            "  Time taken: 4.98 seconds.\n",
            "Processing image 85/103: thyrocare_0_8265.jpg...\n",
            "  Extracted text (first 100 chars): SS er sa 3 2 eRipiuda epwsuleogciehi dial saa Una SeV Eo: 8 a i co . —  eee ee acto) eae aaiataal So...\n",
            "  Time taken: 3.45 seconds.\n",
            "Processing image 86/103: thyrocare_0_8251.jpg...\n",
            "  Extracted text (first 100 chars): cme iT es I | } OHSS ha Lsabinlestaaaea ketice aaa oo tic fone em) De et eR te eas Dae at on or Free...\n",
            "  Time taken: 3.30 seconds.\n",
            "Processing image 87/103: thyrocare_0_8748.jpg...\n",
            "  Extracted text (first 100 chars): rn a 7 ome eee is ee eee ea rte te J Xcel oe yroQ care* eerie rl cain ienanannian TO oe CO RL Rearen...\n",
            "  Time taken: 3.97 seconds.\n",
            "Processing image 88/103: thyrocare_0_8310.jpg...\n",
            "  Extracted text (first 100 chars): eee. MWe iicoree <n i meen, rine lal Riseficcanebane!ss:tnac es — REPBE ~ 2 era noee nN rtd ee oe Pe...\n",
            "  Time taken: 3.29 seconds.\n",
            "Processing image 89/103: thyrocare_0_8394.jpg...\n",
            "  Extracted text (first 100 chars): d . ; ea om Bod F 32 CAP Th Pa me 3] eee yrocare’ SE! fen ~emeeeae SO cai Corporate Office : Trryroc...\n",
            "  Time taken: 3.34 seconds.\n",
            "Processing image 90/103: thyrocare_0_8231.jpg...\n",
            "  Extracted text (first 100 chars): ee eee reed a Rl all “_g pies oh neater mnengaeladinaliparaeiatal , PO ese ep ecella ereaiec hemmed ...\n",
            "  Time taken: 3.90 seconds.\n",
            "Processing image 91/103: thyrocare_0_9047.jpg...\n",
            "  Extracted text (first 100 chars): Eanes cena ld Shree Towers 1, RAA/36, Raghunathpur, TOCcal 5 De ee ee BUR ea  : ele ae ee Eee ee ee ...\n",
            "  Time taken: 5.13 seconds.\n",
            "Processing image 92/103: thyrocare_0_9108.jpg...\n",
            "  Extracted text (first 100 chars): ee ad a spied ae Or Ng h TT wenc-turbhe, > LSB Thyrocar eee ner ere a’ in Oe nas DM ae  DRM Bd e eeS...\n",
            "  Time taken: 3.03 seconds.\n",
            "Processing image 93/103: thyrocare_0_8749.jpg...\n",
            "  Extracted text (first 100 chars): ~/ ; bh sdseouin CA Us) we sates babes nase dh lad pala guested 7 SCE Bena —_ Cs — ee eT Dea sea Cee...\n",
            "  Time taken: 2.69 seconds.\n",
            "Processing image 94/103: thyrocare_0_9076.jpg...\n",
            "  Extracted text (first 100 chars): ROCESSED AT : A dhgraied ree ==CAP Th 7 -37/1, TTC MIDC,Turbhe, gas 7 Pore-Ti thie YyIroO care’ Otic...\n",
            "  Time taken: 3.92 seconds.\n",
            "Processing image 95/103: thyrocare_0_9575.jpg...\n",
            "  Extracted text (first 100 chars): b » rn . Thyrocare A. =CAP ni DP PRR bone bi ay i Feelin yrocare’ eT) ann a SRR d ee ee ee a ee Fads...\n",
            "  Time taken: 3.17 seconds.\n",
            "Processing image 96/103: thyrocare_0_9207.jpg...\n",
            "  Extracted text (first 100 chars): WROCESSED AT : , ’ ) ncaa Thyroca: pie See TOcare Bee ae ete Ree) RL OR a ideal Nii bape aa i ed Lim...\n",
            "  Time taken: 3.85 seconds.\n",
            "Processing image 97/103: thyrocare_0_9447.jpg...\n",
            "  Extracted text (first 100 chars): — eT Peet a ee A i) Freesat Nxt eer ee, Tak Tye Tink Tyree eT ee ete EUR, A aD eo lee TESS SMe re ah...\n",
            "  Time taken: 2.34 seconds.\n",
            "Processing image 98/103: thyrocare_0_9445.jpg...\n",
            "  Extracted text (first 100 chars): vc eee geldaal - aslo ak banca gerpacpienesael hale eaiaeange Sage idincsials Se. ™ h ae ae HEH a ni...\n",
            "  Time taken: 4.96 seconds.\n",
            "Processing image 99/103: thyrocare_0_9833.jpg...\n",
            "  Extracted text (first 100 chars): ea bg eeached _ Ere oy 4 22 ‘h : eae > ecap. Thyrocare Lethe an Se rn Or Ma eR ee Ot ere ma Pe an Es...\n",
            "  Time taken: 2.60 seconds.\n",
            "Processing image 100/103: thyrocare_0_9691.jpg...\n",
            "  Extracted text (first 100 chars): ij Loe ae _ 7 t Saab Wer \\2 ann ’ CT Rae i i Fda Tans yrocare kt a Rod CS oe eed ae ek UR a Lk OREN ...\n",
            "  Time taken: 2.61 seconds.\n",
            "Processing image 101/103: ocr_results.csv...\n",
            "Warning: Could not read image /content/drive/MyDrive/OCR_Project_dataset/ocr_results.csv. Skipping.\n",
            "  Skipped due to preprocessing error.\n",
            "  Time taken: 0.00 seconds.\n",
            "Processing image 102/103: ocr_bbox_results.csv...\n",
            "Warning: Could not read image /content/drive/MyDrive/OCR_Project_dataset/ocr_bbox_results.csv. Skipping.\n",
            "  Skipped due to preprocessing error.\n",
            "  Time taken: 0.00 seconds.\n",
            "Processing image 103/103: data.yaml...\n",
            "Warning: Could not read image /content/drive/MyDrive/OCR_Project_dataset/data.yaml. Skipping.\n",
            "  Skipped due to preprocessing error.\n",
            "  Time taken: 0.00 seconds.\n",
            "\n",
            "Successfully saved extracted data to: /content/drive/MyDrive/ocr_project_results/extracted_thyrocare_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kjxjufpUyotu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yaml # PyYAML is usually pre-installed in Colab\n",
        "\n",
        "# Ensure Google Drive is mounted\n",
        "if not os.path.exists('/content/drive/MyDrive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted.\")\n",
        "else:\n",
        "    print(\"Google Drive already mounted.\")\n",
        "\n",
        "# Define paths\n",
        "base_project_folder = '/content/drive/MyDrive/OCR_Project_dataset/'\n",
        "dataset_main_folder = os.path.join(base_project_folder, 'thyrocare_dataset/')\n",
        "images_folder = os.path.join(dataset_main_folder, 'images/')\n",
        "labels_folder = os.path.join(dataset_main_folder, 'labels/')\n",
        "path_to_yaml = os.path.join(dataset_main_folder, 'dataset.yaml')\n",
        "\n",
        "# Create the main dataset folder and the top-level images and labels folders\n",
        "os.makedirs(dataset_main_folder, exist_ok=True)\n",
        "os.makedirs(images_folder, exist_ok=True)\n",
        "os.makedirs(labels_folder, exist_ok=True)\n",
        "\n",
        "print(f\"Ensured folder exists: {dataset_main_folder}\")\n",
        "print(f\"Ensured folder exists: {images_folder}\")\n",
        "print(f\"Ensured folder exists: {labels_folder}\")\n",
        "\n",
        "# Define the content of the dataset.yaml file\n",
        "# Paths are absolute for clarity and robustness in Colab.\n",
        "yaml_content = {\n",
        "    'train': os.path.join(images_folder, 'train/'), # Path to training images folder\n",
        "    'val': os.path.join(images_folder, 'val/'),     # Path to validation images folder\n",
        "    # Note: YOLO usually expects label folders to mirror image folder structure.\n",
        "    # Some implementations might infer label paths from image paths,\n",
        "    # e.g., if images are in 'images/train', labels are expected in 'labels/train'.\n",
        "    # The paths above define where the *images* are. The label paths are often implicit.\n",
        "\n",
        "    'nc': 4,  # Number of classes\n",
        "    'names': ['test name','technology','value','unit reference range']  # List of class names\n",
        "}\n",
        "\n",
        "# Write the YAML content to the file\n",
        "with open(path_to_yaml, 'w') as f:\n",
        "    yaml.dump(yaml_content, f, sort_keys=False, default_flow_style=None)\n",
        "\n",
        "print(f\"\\n'{path_to_yaml}' created successfully with the following content:\")\n",
        "with open(path_to_yaml, 'r') as f:\n",
        "    print(f.read())\n",
        "\n",
        "print(\"\\nMANUAL ACTIONS REQUIRED NEXT:\")\n",
        "print(\"1.  **Create `train` and `val` subdirectories:**\")\n",
        "print(f\"    - Go to your Google Drive. Inside '{images_folder}', create two subfolders: `train` and `val`.\")\n",
        "print(f\"    - Inside '{labels_folder}', create two subfolders: `train` and `val`.\")\n",
        "print(\"\\n2.  **Populate these folders:**\")\n",
        "print(\"    - Distribute your ~100 images into the `images/train/` and `images/val/` folders (e.g., 80 for train, 20 for val).\")\n",
        "print(\"    - Start your annotation process for all these images.\")\n",
        "print(\"    - As you annotate each image, save its corresponding YOLO annotation `.txt` file in the `labels/train/` or `labels/val/` folder that matches where the image is.\")\n",
        "print(\"      (e.g., if `reportX.jpg` is in `images/train/`, then `reportX.txt` should be in `labels/train/`).\")\n",
        "print(\"\\n3.  **Confirm class order for annotations:**\")\n",
        "print(\"      0: test Name, 1: technology, 2: value, 3: unit reference range\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIWcvWLN8f2s",
        "outputId": "889d4722-1074-46d1-bdf0-a873f8ac4331"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive already mounted.\n",
            "Ensured folder exists: /content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/\n",
            "Ensured folder exists: /content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/\n",
            "Ensured folder exists: /content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/labels/\n",
            "\n",
            "'/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/dataset.yaml' created successfully with the following content:\n",
            "train: /content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/\n",
            "val: /content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/val/\n",
            "nc: 4\n",
            "names: [test name, technology, value, unit reference range]\n",
            "\n",
            "\n",
            "MANUAL ACTIONS REQUIRED NEXT:\n",
            "1.  **Create `train` and `val` subdirectories:**\n",
            "    - Go to your Google Drive. Inside '/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/', create two subfolders: `train` and `val`.\n",
            "    - Inside '/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/labels/', create two subfolders: `train` and `val`.\n",
            "\n",
            "2.  **Populate these folders:**\n",
            "    - Distribute your ~100 images into the `images/train/` and `images/val/` folders (e.g., 80 for train, 20 for val).\n",
            "    - Start your annotation process for all these images.\n",
            "    - As you annotate each image, save its corresponding YOLO annotation `.txt` file in the `labels/train/` or `labels/val/` folder that matches where the image is.\n",
            "      (e.g., if `reportX.jpg` is in `images/train/`, then `reportX.txt` should be in `labels/train/`).\n",
            "\n",
            "3.  **Confirm class order for annotations:**\n",
            "      0: test Name, 1: technology, 2: value, 3: unit reference range\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ihRG9bxqBXdt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training\n",
        "\n",
        "Task 3.1: Train YOLO Model"
      ],
      "metadata": {
        "id": "8aT0c0j6_brx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_dqA0WnmTB0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjcAtarb4JlI",
        "outputId": "7e5cd4dc-c293-4ba9-c666-74cf1e874e88"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.134-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.134-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m779.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.134 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO  # Ultralytics YOLOv8 (or v5 - install if needed)\n",
        "import os\n",
        "\n",
        "# 1. Load a pre-trained model (YOLOv8 strongly recommended)\n",
        "model = YOLO('yolov8n.pt')  # or 'yolov5n.pt' if you prefer v5\n",
        "\n",
        "# 2. Define data.yaml path (already created)\n",
        "data_yaml_path = '/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/dataset.yaml'\n",
        "\n",
        "# 3. Output directory for trained models\n",
        "output_model_dir = '/content/drive/MyDrive/OCR_Project_dataset/models'\n",
        "os.makedirs(output_model_dir, exist_ok=True)\n",
        "\n",
        "# 4. Train the model\n",
        "results = model.train(data=data_yaml_path, epochs=100, imgsz=640)\n",
        "\n",
        "# 5. Save the trained model\n",
        "trained_model_path = os.path.join(output_model_dir, 'thyrocare_yolov8n_trained.pt') # Or yolov5n\n",
        "model.save(trained_model_path)\n",
        "\n",
        "print(f\"Trained model saved to: {trained_model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nseY0-fT3-h8",
        "outputId": "ddd70290-53dc-4124-ece1-127c8c33ba64"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 89.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.134 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/dataset.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 21.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model summary: 129 layers, 3,011,628 parameters, 3,011,612 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 88.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.5±0.2 ms, read: 0.2±0.0 MB/s, size: 51.9 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/labels/train... 80 images, 0 backgrounds, 80 corrupt: 100%|██████████| 80/80 [01:00<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_1001.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_1174.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_122.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_123.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_1248.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_1374.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_1433.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_1711.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_1861.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_1915.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_2177.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_2300.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_2505.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_2649.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_2691.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_2737.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_2838.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_2841.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_2866.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_2885.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_2987.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_3333.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_3414.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_3439.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_3558.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_36 (1).jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_3753.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_3804.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_3813.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_4046.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_421.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_4385.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_4468.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_447.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_4498.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_4523.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_4557.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_4618.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_4670.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_4683.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_4748.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_4790.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_4979.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_5074.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_511.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_517.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_532.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_5338.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_5357.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_5503.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_5608.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_5640.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_5816.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_5858.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_5879.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_5896.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_5928.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_6185.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_6214.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_6222.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_640.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_657.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_6698.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_6716.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_6723.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_6743.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_6884.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_7075.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_7082.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_7083.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_7109.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_7219.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_757.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_7571.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_7601.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_7635.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_7758.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_7791.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_838.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/train/thyrocare_0_912.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/labels/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "No valid images found in /content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/labels/train.cache. Images with incorrectly formatted labels are ignored. See https://docs.ultralytics.com/datasets for dataset formatting guidance.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-77a6b96f49c8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# 4. Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_yaml_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# 5. Save the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mworld_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_ddp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# number of batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_setup_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;31m# Dataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         self.train_loader = self.get_dataloader(\n\u001b[0m\u001b[1;32m    292\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOCAL_RANK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/models/yolo/detect/train.py\u001b[0m in \u001b[0;36mget_dataloader\u001b[0;34m(self, dataset_path, batch_size, rank, mode)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Mode must be 'train' or 'val', not {mode}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch_distributed_zero_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# init dataset *.cache only once if DDP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rect\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/models/yolo/detect/train.py\u001b[0m in \u001b[0;36mbuild_dataset\u001b[0;34m(self, img_path, mode, batch)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \"\"\"\n\u001b[1;32m     64\u001b[0m         \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_yolo_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/build.py\u001b[0m in \u001b[0;36mbuild_yolo_dataset\u001b[0;34m(cfg, img_path, batch, data, mode, rect, stride, multi_modal)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;34m\"\"\"Build and return a YOLO dataset based on configuration parameters.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLOMultiModalDataset\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmulti_modal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mYOLODataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     return dataset(\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mimg_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, task, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_segments\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_keypoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Can not use both segments and keypoints.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"channels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcache_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./labels.cache\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img_path, imgsz, cache, augment, hyp, prefix, rect, batch_size, stride, pad, single_cls, classes, fraction, channels)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_img_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# single_cls and include_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mni\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# number of images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/dataset.py\u001b[0m in \u001b[0;36mget_labels\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0;34mf\"No valid images found in {cache_path}. Images with incorrectly formatted labels are ignored. {HELP_URL}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No valid images found in /content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/labels/train.cache. Images with incorrectly formatted labels are ignored. See https://docs.ultralytics.com/datasets for dataset formatting guidance."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3.2: Model Validation"
      ],
      "metadata": {
        "id": "xPp2EPPF4lzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Validate the model\n",
        "metrics = model.val(data=data_yaml_path)  # Uses the validation set in data.yaml\n",
        "print(\"Validation Metrics:\", metrics.results_dict)\n",
        "\n",
        "# 2. Visualize Predictions (optional) - Saves images with bounding boxes\n",
        "output_predict_dir = '/content/drive/MyDrive/OCR_Project_dataset/results/validation_predictions'\n",
        "os.makedirs(output_predict_dir, exist_ok=True)\n",
        "model.predict(source='/content/drive/MyDrive/OCR_Project_dataset/images/val', save=True, name='val_preds', exist_ok=True)\n",
        "\n",
        "#   #  The predicted images are saved in a 'runs/predict' directory.  Move them:\n",
        "#   import shutil\n",
        "#   source_predict_dir = 'runs/predict/val_preds' # Adjust if needed\n",
        "#   if os.path.exists(source_predict_dir):\n",
        "#       for file_name in os.listdir(source_predict_dir):\n",
        "#           shutil.move(os.path.join(source_predict_dir, file_name), output_predict_dir)\n",
        "#       shutil.rmtree(source_predict_dir) # Clean up\n",
        "#   print(f\"Validation predictions saved to: {output_predict_dir}\")"
      ],
      "metadata": {
        "id": "aM0CfQos4wKR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        },
        "outputId": "b9e30119-cf90-4e03-b258-6c6b30226a68"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.134 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,006,428 parameters, 13,260 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.5±0.2 ms, read: 0.1±0.0 MB/s, size: 50.1 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/labels/val... 20 images, 0 backgrounds, 20 corrupt: 100%|██████████| 20/20 [00:13<00:00,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/val/thyrocare_0_7805.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/val/thyrocare_0_8214.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/val/thyrocare_0_8231.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/val/thyrocare_0_8251.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/val/thyrocare_0_8265.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/val/thyrocare_0_8302.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/val/thyrocare_0_8310.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/val/thyrocare_0_8394.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/val/thyrocare_0_8491.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/val/thyrocare_0_8748.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/val/thyrocare_0_8749.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/val/thyrocare_0_9047.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/val/thyrocare_0_9076.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/val/thyrocare_0_9108.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/val/thyrocare_0_9207.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/val/thyrocare_0_9445.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/val/thyrocare_0_9447.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/val/thyrocare_0_9575.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/val/thyrocare_0_9691.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/images/val/thyrocare_0_9833.jpg: ignoring corrupt image/label: Label class 18 exceeds dataset class count 4. Possible class labels are 0-3\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "No valid images found in /content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/labels/val.cache. Images with incorrectly formatted labels are ignored. See https://docs.ultralytics.com/datasets for dataset formatting guidance.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-810c5dc36fe7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 1. Validate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_yaml_path\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Uses the validation set in data.yaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation Metrics:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 2. Visualize Predictions (optional) - Saves images with bounding boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mval\u001b[0;34m(self, validator, **kwargs)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0mvalidator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalidator\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m         \u001b[0mvalidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/validator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, trainer, model)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m  \u001b[0;31m# used in get_dataloader() for padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/models/yolo/detect/val.py\u001b[0m in \u001b[0;36mget_dataloader\u001b[0;34m(self, dataset_path, batch_size)\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataloader\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \"\"\"\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# return dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/models/yolo/detect/val.py\u001b[0m in \u001b[0;36mbuild_dataset\u001b[0;34m(self, img_path, mode, batch)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mYOLO\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \"\"\"\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_yolo_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/build.py\u001b[0m in \u001b[0;36mbuild_yolo_dataset\u001b[0;34m(cfg, img_path, batch, data, mode, rect, stride, multi_modal)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;34m\"\"\"Build and return a YOLO dataset based on configuration parameters.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLOMultiModalDataset\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmulti_modal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mYOLODataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     return dataset(\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mimg_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, task, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_segments\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_keypoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Can not use both segments and keypoints.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"channels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcache_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./labels.cache\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img_path, imgsz, cache, augment, hyp, prefix, rect, batch_size, stride, pad, single_cls, classes, fraction, channels)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_img_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# single_cls and include_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mni\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# number of images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/dataset.py\u001b[0m in \u001b[0;36mget_labels\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0;34mf\"No valid images found in {cache_path}. Images with incorrectly formatted labels are ignored. {HELP_URL}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No valid images found in /content/drive/MyDrive/OCR_Project_dataset/thyrocare_dataset/labels/val.cache. Images with incorrectly formatted labels are ignored. See https://docs.ultralytics.com/datasets for dataset formatting guidance."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "85tbWP0u45Na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Inference and Post-Processing\n",
        "# Task: Detect text regions with YOLO, crop, OCR with Tesseract, and structure the data."
      ],
      "metadata": {
        "id": "uCeXVnED5BXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# 1. Load the trained YOLO model\n",
        "trained_model_path = '/content/drive/MyDrive/OCR_Project_dataset/models/thyrocare_yolov8n_trained.pt'  # Adjust path!\n",
        "model = YOLO(trained_model_path)\n",
        "\n",
        "def process_image(image_path):\n",
        "    # 2. Run YOLO inference\n",
        "    results = model.predict(image_path)\n",
        "    boxes = results[0].boxes.xyxy.cpu().numpy().astype(int)\n",
        "    class_ids = results[0].boxes.cls.cpu().numpy().astype(int)\n",
        "    cropped_data = []\n",
        "\n",
        "    # 3. Crop and OCR\n",
        "    img = cv2.imread(image_path)\n",
        "    for i, (x1, y1, x2, y2) in enumerate(boxes):\n",
        "        crop = img[y1:y2, x1:x2]\n",
        "        preprocessed_crop = preprocess_image_for_ocr(crop)  # Your preprocessing\n",
        "        if preprocessed_crop is not None:\n",
        "            text = pytesseract.image_to_string(Image.fromarray(preprocessed_crop)).strip()\n",
        "            cropped_data.append({'class': class_ids[i], 'text': text, 'bbox': (x1, y1, x2, y2)})\n",
        "    return cropped_data\n",
        "\n",
        "# 4. Process all images and create structured output\n",
        "all_extracted_data = []\n",
        "for image_file in os.listdir('/content/drive/MyDrive/OCR_Project_dataset/images/val'):  # Or a test folder\n",
        "    if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "        image_path = os.path.join('/content/drive/MyDrive/OCR_Project_dataset/images/val', image_file)\n",
        "        extracted_data = process_image(image_path)\n",
        "        all_extracted_data.append({'image': image_file, 'data': extracted_data})\n",
        "\n",
        "# 5. Structure the data (example - adapt to your specific report layout!)\n",
        "structured_results = []\n",
        "for item in all_extracted_data:\n",
        "    image_name = item['image']\n",
        "    data = item['data']\n",
        "    #  Assume a simple table-like structure:  Find bounding boxes in a logical order\n",
        "    test_name = next((d['text'] for d in data if d['class'] == 0), None)\n",
        "    value = next((d['text'] for d in data if d['class'] == 1), None)\n",
        "    unit = next((d['text'] for d in data if d['class'] == 2), None)\n",
        "    ref_value = next((d['text'] for d in data if d['class'] == 3), None)\n",
        "    structured_results.append({'image': image_name, 'Test Name': test_name, 'Value': value, 'Unit': unit, 'Reference Value': ref_value})\n",
        "\n",
        "df_results = pd.DataFrame(structured_results)\n",
        "output_csv_path = '/content/drive/MyDrive/OCR_Project_dataset/results/structured_ocr_output.csv'\n",
        "df_results.to_csv(output_csv_path, index=False)\n",
        "print(f\"Structured data saved to: {output_csv_path}\")"
      ],
      "metadata": {
        "id": "Kbs3qv5P5DLv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "77b60800-a851-4cfc-babe-c1265b033beb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/OCR_Project_dataset/models/thyrocare_yolov8n_trained.pt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1bfba4b5f1fb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 1. Load the trained YOLO model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrained_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/OCR_Project_dataset/models/thyrocare_yolov8n_trained.pt'\u001b[0m  \u001b[0;31m# Adjust path!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/models/yolo/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m# Continue with default YOLO initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# Delete super().training for accessing self.model.training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self, weights, task)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffix\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\".pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattempt_load_one_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"task\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_ckpt_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mattempt_load_one_weight\u001b[0;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \"\"\"\n\u001b[0;32m-> 1317\u001b[0;31m     \u001b[0mckpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_safe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# load ckpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mDEFAULT_CFG_DICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_args\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# combine model and default args, preferring model args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ema\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# FP32 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mtorch_safe_load\u001b[0;34m(weight, safe_only)\u001b[0m\n\u001b[1;32m   1220\u001b[0m                     \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe_pickle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m                 \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# e.name is missing module name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/utils/patches.py\u001b[0m in \u001b[0;36mtorch_load\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"weights_only\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_torch_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/OCR_Project_dataset/models/thyrocare_yolov8n_trained.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Evaluation and Optimization\n",
        "\n",
        "# Task 5.1: Evaluation"
      ],
      "metadata": {
        "id": "D6O7hMyH5cj9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1ce3Lja95wvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install jiwer"
      ],
      "metadata": {
        "id": "hmszeqfb5xn_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73158e98-54db-4402-f9cd-3ee55041cbc5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-3.1.0 rapidfuzz-3.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from jiwer import measure  # For CER/WER (install: pip install jiwer)\n",
        "\n",
        "def evaluate_ocr(ground_truth_csv, ocr_output_csv):\n",
        "    gt_df = pd.read_csv(ground_truth_csv)\n",
        "    ocr_df = pd.read_csv(ocr_output_csv)\n",
        "\n",
        "    merged_df = pd.merge(gt_df, ocr_df, on='image', suffixes=('_gt', '_ocr'), how='inner') # Adjust 'on' key\n",
        "\n",
        "    cer_list = []\n",
        "    wer_list = []\n",
        "\n",
        "    for index, row in merged_df.iterrows():\n",
        "        gt_text = str(row['Test Name_gt']) + \" \" + str(row['Value_gt']) + \" \" + str(row['Unit_gt']) + \" \" + str(row['Reference Value_gt'])  # Concatenate ground truth text\n",
        "        ocr_text = str(row['Test Name_ocr']) + \" \" + str(row['Value_ocr']) + \" \" + str(row['Unit_ocr']) + \" \" + str(row['Reference Value_ocr']) # Concatenate OCR text\n",
        "\n",
        "        # Calculate CER and WER\n",
        "        cer = measure(gt_text, ocr_text).cer\n",
        "        wer = measure(gt_text, ocr_text).wer\n",
        "        cer_list.append(cer)\n",
        "        wer_list.append(wer)\n",
        "\n",
        "    avg_cer = sum(cer_list) / len(cer_list) if cer_list else 0\n",
        "    avg_wer = sum(wer_list) / len(wer_list) if wer_list else 0\n",
        "\n",
        "    print(f\"Average CER: {avg_cer:.4f}\")\n",
        "    print(f\"Average WER: {avg_wer:.4f}\")\n",
        "\n",
        "# Example Usage:\n",
        "ground_truth_csv_path = '/content/drive/MyDrive/OCR_Project_dataset/ground_truth.csv'  # You'll need to create this!\n",
        "ocr_output_csv_path = '/content/drive/MyDrive/OCR_Project_dataset/results/structured_ocr_output.csv'\n",
        "evaluate_ocr(ground_truth_csv_path, ocr_output_csv)"
      ],
      "metadata": {
        "id": "dpv5Q2FF5jNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 5.2: Optimization (Conceptual - Code Fragments)\n",
        "\n",
        "Data Augmentation (YOLO): YOLOv8/v5 have built-in augmentation.  Tweak these in model.train():"
      ],
      "metadata": {
        "id": "jUDI_GY15-Zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(data=data_yaml_path, epochs=100, imgsz=640,\n",
        "            flipud=0.5,  # Vertical flip\n",
        "            lr0=0.01)   # Learning rate (example)"
      ],
      "metadata": {
        "id": "F-9Aa6466WVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Tuning: Modify your preprocess_image_for_ocr() function.  There's no single \"best\" – experiment!"
      ],
      "metadata": {
        "id": "eFX5eQEp6abf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image_for_ocr(image):  #  Now takes the image directly\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)  #  Bigger blur\n",
        "    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU) # Inverted thresholding\n",
        "    #  ...  other processing\n",
        "    return thresh"
      ],
      "metadata": {
        "id": "sFquUWaY6hah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tesseract Configuration: Pass different configurations to pytesseract.image_to_string():"
      ],
      "metadata": {
        "id": "y9zf96mZ6s6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = pytesseract.image_to_string(Image.fromarray(preprocessed_crop),\n",
        "                            config='--psm 6 --oem 1')  # Different Page Segmentation Mode, OCR Engine Mode"
      ],
      "metadata": {
        "id": "Hnod1B1d6xlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ivNcWpVE6gDk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}